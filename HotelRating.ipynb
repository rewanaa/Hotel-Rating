{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64930f3f",
   "metadata": {
    "id": "64930f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\personal\\programs\\anaconda\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\personal\\programs\\anaconda\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\personal\\programs\\anaconda\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders\n",
    "import sklearn.preprocessing as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot  as plt\n",
    "import math\n",
    "import pickle\n",
    "from os.path import exists\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import r_regression, f_classif , chi2 , mutual_info_classif , SelectKBest\n",
    "from tkinter import Tk, filedialog\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import kstest, norm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "import category_encoders as b\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.feature_selection import f_classif,r_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import uniform\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import statsmodels.regression.linear_model as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#r_regression, f_classif, SelectKBest\n",
    "from sklearn.feature_selection import r_regression, f_classif , chi2 , mutual_info_classif , SelectKBest\n",
    "from scipy.stats import kendalltau\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d2d28",
   "metadata": {
    "id": "4c3d2d28"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2e558",
   "metadata": {
    "id": "d2e2e558"
   },
   "source": [
    "### Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e150a2e9",
   "metadata": {
    "id": "e150a2e9"
   },
   "outputs": [],
   "source": [
    "def parseCountry(x):\n",
    "    addr = x.split()\n",
    "    if len(addr) <= 2:\n",
    "        return x\n",
    "    if addr[-2] == 'United' and addr[-1] == 'Kingdom':\n",
    "        return addr[-2] + ' ' + addr[-1]\n",
    "    else:\n",
    "        return addr[-1]\n",
    "def makeColumn(row):\n",
    "    if row[\"Hotel_Address\"] == row[\"Reviewer_Nationality\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def PreprocessAddress(dataset):\n",
    "  dataset['Reviewer_Nationality'].replace(' Israel ', 'Palestine', inplace=True)\n",
    "  dataset[\"Hotel_Address\"] = dataset[\"Hotel_Address\"].apply(parseCountry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36898b",
   "metadata": {
    "id": "8c36898b"
   },
   "source": [
    "### Remove 'Days' from days since review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9694b994",
   "metadata": {
    "id": "9694b994"
   },
   "outputs": [],
   "source": [
    "def parseNDays(x):\n",
    "    if type(x) is str:\n",
    "      date = x.split()\n",
    "      return int(date[0])\n",
    "    return x\n",
    "def PreprocessDays(dataset):\n",
    "  dataset[\"days_since_review\"] = dataset[\"days_since_review\"].apply(parseNDays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd35be",
   "metadata": {
    "id": "0fdd35be"
   },
   "source": [
    "### Review date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfa22b8",
   "metadata": {
    "id": "cbfa22b8"
   },
   "outputs": [],
   "source": [
    "def parseDate(x):\n",
    "    parsedDate = datetime.strptime(x.strip(),'%m/%d/%Y')\n",
    "    return parsedDate.timestamp() / 3600\n",
    "def preprocessDates(dataset):\n",
    "  dataset[\"Review_month\"] = pd.to_datetime(dataset['Review_Date']).dt.month\n",
    "  dataset['Review_Date'] = dataset['Review_Date'].apply(parseDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9e235",
   "metadata": {
    "id": "23b9e235"
   },
   "source": [
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354f3e7c",
   "metadata": {
    "id": "354f3e7c"
   },
   "outputs": [],
   "source": [
    "room_type =  [\"Privilege \",\"2 rooms\",'Cosy' , 'Luxury',\"Apartment\",'Classic','Bungalow', 'Villa', 'Penthouse', 'Superior', 'Studio', 'Connecting', 'Suite', 'Deluxe', 'Standard','Executive',\"Economy\",'Family Room',\"Club\",\"City\",\"Guest\", \"Double Room\", \" Twin Room\"]\n",
    "def extract_Room(arr):\n",
    "    for val in arr:\n",
    "        for word in room_type:\n",
    "            if word in val:\n",
    "                return word\n",
    "    return \"None\"            # i used other as there is a lot of data that doesn't say the type of room, and there is a lot of types too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "MMd2O1aUcYRq",
   "metadata": {
    "id": "MMd2O1aUcYRq"
   },
   "outputs": [],
   "source": [
    "def convert_to_array(x):\n",
    "    return ast.literal_eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2elW57Irca7s",
   "metadata": {
    "id": "2elW57Irca7s"
   },
   "outputs": [],
   "source": [
    "def extract_Nights(arr):\n",
    "    word = r'Stayed (\\d+) night(?:s)?'                      # define the String that we want to Extract\n",
    "    for val in arr:                                         # becasue it's an array and the index is unknown you check every element in it\n",
    "        if isinstance(val, str) and re.search(word, val):   # the isinstance check if string, and re.search find patterns between two strings\n",
    "            stay = int(re.search(word, val).group(1))       # Extect the number from the word, and the augment 1 is to return the first match\n",
    "            return stay\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21fd4f38",
   "metadata": {
    "id": "21fd4f38"
   },
   "outputs": [],
   "source": [
    "room_size = ['Double','Twin','Single',\"Triple\",\"Quadruple\",\"Quintuple\",\"King\",\"Queen\",'queen']\n",
    "def extract_Room(arr):\n",
    "    for val in arr:\n",
    "        for word in room_size:\n",
    "            if word in val:\n",
    "                return word\n",
    "    return \"None\"        # same as room type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b82248a8",
   "metadata": {
    "id": "b82248a8"
   },
   "outputs": [],
   "source": [
    "room_size = ['Family with','Couple','Solo traveler','Group','Travelers with friends']\n",
    "def extract_customer(arr):\n",
    "    for val in arr:\n",
    "        for word in room_size:\n",
    "            if word in val:\n",
    "                return val\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684ba5e8",
   "metadata": {
    "id": "684ba5e8"
   },
   "outputs": [],
   "source": [
    "device_type = ['Submitted']\n",
    "def extract_submit(arr):\n",
    "    for val in arr:\n",
    "        for word in device_type:\n",
    "            if word in val:\n",
    "                return 1\n",
    "    return 0  # I found only submitted by phone in this dataset, so binary is solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797d55df",
   "metadata": {
    "id": "797d55df"
   },
   "outputs": [],
   "source": [
    "def PreprocessTags(dataset):\n",
    "  dataset['Tags'] = dataset['Tags'].apply(convert_to_array)\n",
    "  Leisure = dataset[\"Tags\"].apply(lambda x: \" Leisure trip \" in x)\n",
    "  Business = dataset[\"Tags\"].apply(lambda x: \" Business trip \" in x)\n",
    "  dataset.loc[Leisure, 'trip_type'] = 0\n",
    "  dataset.loc[Business, 'trip_type'] = 1\n",
    "  df_exploded = dataset.explode('Tags')\n",
    "  dataset['duration'] = dataset['Tags'].apply(extract_Nights)\n",
    "  dataset[\"room_type\"] = dataset['Tags'].apply(extract_Room)\n",
    "  dataset[\"bed_type\"] = dataset['Tags'].apply(extract_Room)\n",
    "  dataset[\"customer_type\"] = dataset['Tags'].apply(extract_customer)\n",
    "  dataset[\"submit\"] = dataset['Tags'].apply(extract_submit)\n",
    "  dataset.drop(\"Tags\",axis =1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a188a1",
   "metadata": {
    "id": "77a188a1"
   },
   "source": [
    "### Replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc932d9",
   "metadata": {
    "id": "0cc932d9"
   },
   "outputs": [],
   "source": [
    "\n",
    "def getPlaceHolders(data):\n",
    "  placeholders = {}\n",
    "  dataInfo = data.dtypes\n",
    "  for col in data.columns:\n",
    "    if dataInfo[col] == 'object':\n",
    "      placeholders[col] = data[col].mode()\n",
    "    else:\n",
    "      # Check for normality using the Kolmogorov-Smirnov test\n",
    "      stat, p_value = kstest(data[col].dropna(), 'norm')\n",
    "      is_normal = p_value >= 0.05\n",
    "      # Fill missing data with mean or median depending on normality\n",
    "      if is_normal:\n",
    "        placeholders[col] = data[col].mean()\n",
    "      else:\n",
    "        placeholders[col] = data[col].median()\n",
    "  return placeholders\n",
    "def replace_null_values(dataset,placeholders):\n",
    "    for col in dataset.columns:\n",
    "      if not (col in placeholders):\n",
    "          continue\n",
    "      dataset[col] = dataset[col].fillna(value= placeholders[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lRaAtcg6jfe6",
   "metadata": {
    "id": "lRaAtcg6jfe6"
   },
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "o4dHVBGQkPQA",
   "metadata": {
    "id": "o4dHVBGQkPQA"
   },
   "outputs": [],
   "source": [
    "bad_red = [\"Breakfast\",\"Location\",\"Everything\",\"Small room,Expensive\",\"Staff\",\"Room size\",\"Very small room\",\"breakfast\",\"small room\",\"Small room\",\"Parking\",\"Room too small\",\n",
    "\"See above\",\"As above\",\"Expensive breakfast\",\"Pillows\",\"No parking\",\"Size of the room\",\"Room very small\",\"Small bathroom\",\"Breakfast not included,Wifi\",\"location\",\"The price\",\"Very small rooms\",\n",
    "\"No gym\",\"Size of room\",\"Room was small\",\"Not applicable\",\"Noise\",\"Price of breakfast\",\"Room was very small\",\"Breakfast too expensive\",\"Location\" ,\"Bathroom\",\"No pool\",\"Everything\" ]\n",
    "\n",
    "good = [\"No Negative\",\"Nothing\"]\n",
    "# df\n",
    "substring = [\"No Negative\",\"Nothing\"]\n",
    "# Apply lambda function to check if substring exists in each element of the 'text' column\n",
    "def neg(x):\n",
    "  res = []\n",
    "  for i in range(100):\n",
    "    for word in good:\n",
    "      if x[i] in word:\n",
    "        \"\"  \n",
    "      else:\n",
    "        res.append(x[i])\n",
    "  return res\n",
    "def reviewClassifier(review):\n",
    "    if len(review) > 16: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def PreprocessReviews(dataset):\n",
    "   #t = dataset['Negative_Review'].apply(lambda x: neg(x))\n",
    "   #dataset[t][\"Negative_Review\"].count()\n",
    "   #t = pd.DataFrame(dataset[\"Negative_Review\"].value_counts())\n",
    "   #neg(t.index)\n",
    "   #dataset.drop(\"Negative_Review\",axis = 1,inplace = True)\n",
    "   #dataset.drop(\"Positive_Review\",axis=1,inplace = True)\n",
    "  classifyReviews = np.vectorize(reviewClassifier)\n",
    "  dataset[[\"Positive_Review\",\"Negative_Review\"]] = classifyReviews(dataset[[\"Positive_Review\",\"Negative_Review\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220a380",
   "metadata": {
    "id": "f220a380"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8NssDeMptmei",
   "metadata": {
    "id": "8NssDeMptmei"
   },
   "outputs": [],
   "source": [
    "def EncodeLR(dataset):\n",
    "    dataset.drop('Hotel_Name',axis=1,inplace=True)\n",
    "    cat_feature = 'Reviewer_Nationality'\n",
    "    # Compute the frequency of each category in the categorical feature\n",
    "    freq = dataset[cat_feature].value_counts(normalize=True)\n",
    "    # Map each category in the feature to its frequency\n",
    "    dataset[cat_feature] = dataset[cat_feature].map(freq)\n",
    "    encoder = OneHotEncoder()\n",
    "    if exists('LRHotEncoder.sav'):\n",
    "        encoder = pickle.load(open('LRHotEncoder.sav','rb'))\n",
    "        encoded_data = encoder.transform(dataset[['Hotel_Address']]).toarray() \n",
    "        # Create a new DataFrame with the encoded data\n",
    "        encoded_dataset = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Hotel_Address']))\n",
    "        # Concatenate the original DataFrame with the encoded DataFrame\n",
    "        dataset = pd.concat([dataset, encoded_dataset], axis=1)\n",
    "        # Fit and transform the data\n",
    "        encoded_data = encoder.transform(dataset[['customer_type']]).toarray()\n",
    "        # Create a new DataFrame with the encoded data\n",
    "        encoded_dataset = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['customer_type']))\n",
    "        # Concatenate the original DataFrame with the encoded DataFrame\n",
    "        dataset = pd.concat([dataset, encoded_dataset], axis=1)\n",
    "    else:\n",
    "        encoded_data = encoder.fit_transform(dataset[['Hotel_Address']]).toarray() \n",
    "        # Create a new DataFrame with the encoded data\n",
    "        encoded_dataset = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['Hotel_Address']))\n",
    "        # Concatenate the original DataFrame with the encoded DataFrame\n",
    "        dataset = pd.concat([dataset, encoded_dataset], axis=1)\n",
    "        # Fit and transform the data\n",
    "        encoded_data = encoder.fit_transform(dataset[['customer_type']]).toarray()\n",
    "        # Create a new DataFrame with the encoded data\n",
    "        encoded_dataset = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(['customer_type']))\n",
    "        # Concatenate the original DataFrame with the encoded DataFrame\n",
    "        dataset = pd.concat([dataset, encoded_dataset], axis=1)\n",
    "        pickle.dump(encoder,open('LRHotEnconder.sav','wb'))\n",
    "    # Drop the original 'Hotel_Address' column\n",
    "    dataset = dataset.drop('customer_type', axis=1)\n",
    "    # Drop the original 'Hotel_Address' column\n",
    "    dataset = dataset.drop('Hotel_Address', axis=1)\n",
    "    # Create a LabelEncoder object\n",
    "    encoder = LabelEncoder()\n",
    "    if exists('LRLabelEncoder.sav'):\n",
    "        encoder = pickle.load(open('LRLabelEncoder.sav','rb'))\n",
    "        # Fit and transform the data\n",
    "        dataset[\"bed_type\"] = encoder.transform(dataset[\"bed_type\"])\n",
    "        dataset[\"room_type\"] = encoder.transform(dataset[\"room_type\"])\n",
    "    else:\n",
    "        # Fit and transform the data\n",
    "        dataset[\"bed_type\"] = encoder.fit_transform(dataset[\"bed_type\"])\n",
    "        dataset[\"room_type\"] = encoder.fit_transform(dataset[\"room_type\"])\n",
    "        pickle.dump(encoder,open('LRLabelEncoder.sav','wb'))\n",
    "    dataset.head()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afc8df71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afc8df71",
    "outputId": "0ede071f-fc12-4773-af3b-40ef412c8187"
   },
   "outputs": [],
   "source": [
    "def fun(x):\n",
    "  if x == 0:\n",
    "    return 3\n",
    "  elif x == 1:\n",
    "    return 7\n",
    "  elif x == 2:\n",
    "    return 5\n",
    "  elif x == 3:\n",
    "    return 6\n",
    "  elif x == 4:\n",
    "    return 1\n",
    "  elif x == 5:\n",
    "    return 4\n",
    "  elif x == 6:\n",
    "    return 2\n",
    "  else:\n",
    "    return 0\n",
    "def EncodeGB(dataset):\n",
    "  dataset = pd.get_dummies(dataset, columns=['Hotel_Address'])\n",
    "  dataset = pd.get_dummies(dataset, columns=['customer_type'])\n",
    "  encoder = ce.BinaryEncoder(cols=['Reviewer_Nationality'])\n",
    "  if exists('Binary1GB.sav'):\n",
    "    encoder = pickle.load(open('Binary1GB.sav','rb'))\n",
    "    dataset = encoder.transform(dataset)\n",
    "  else:\n",
    "    dataset = encoder.fit_transform(dataset)\n",
    "    pickle.dump(encoder,open('Binary1GB.sav','wb'))\n",
    "  # mapping = {'Unknown':0,'Single': 1, 'Twin': 2, 'Double': 3, 'Triple': 4, 'Quadruple': 5, 'Queen':6,'King':7,}\n",
    "  le = LabelEncoder()\n",
    "  if exists('LabelEncoderGB.sav'):\n",
    "    le = pickle.load(open('LabelEncoderGB.sav','rb'))\n",
    "    dataset[\"bed_type\"] = le.transform(dataset[\"bed_type\"])\n",
    "  else:\n",
    "    dataset[\"bed_type\"] = le.fit_transform(dataset[\"bed_type\"])\n",
    "    pickle.dump(le,open('LabelEncoderGB.sav','wb'))\n",
    "  dataset[\"bed_type\"] = dataset[\"bed_type\"].apply(fun)\n",
    "  encoder = ce.BinaryEncoder(cols=['room_type','Hotel_Name'])\n",
    "  if exists('Binary2GB.sav'):\n",
    "    encoder = pickle.load(open('Binary2GB.sav','rb'))\n",
    "    dataset = encoder.transform(dataset)\n",
    "  else:\n",
    "    dataset = encoder.fit_transform(dataset)\n",
    "    pickle.dump(encoder,open('Binary2GB.sav','wb'))\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Su2IKhtbWIHA",
   "metadata": {
    "id": "Su2IKhtbWIHA"
   },
   "outputs": [],
   "source": [
    "def Encode(dataset):\n",
    "  encoder = pp.OrdinalEncoder(dtype = np.int32)\n",
    "  encodedColumns = list()\n",
    "  for i in dataset:\n",
    "      if dataset.dtypes[i] == 'object':\n",
    "        encodedColumns.append(i)\n",
    "  dataset[encodedColumns] = encoder.fit_transform(dataset[encodedColumns])\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b1a2f",
   "metadata": {
    "id": "a32b1a2f"
   },
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d29246",
   "metadata": {
    "id": "d5d29246"
   },
   "outputs": [],
   "source": [
    "def Normalization(dataset):\n",
    "  numericalColumns = list()\n",
    "  for i in dataset:\n",
    "    if dataset.dtypes[i] != 'object':\n",
    "       numericalColumns.append(i)\n",
    "  dataset[numericalColumns] = pp.MinMaxScaler((0,1)).fit_transform(dataset[numericalColumns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TSJO5OPzWJ3b",
   "metadata": {
    "id": "TSJO5OPzWJ3b"
   },
   "source": [
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bnlVcIZNhmz1",
   "metadata": {
    "id": "bnlVcIZNhmz1"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(dataset):\n",
    "  PreprocessAddress(dataset)\n",
    "  PreprocessDays(dataset)\n",
    "  preprocessDates(dataset)\n",
    "  PreprocessTags(dataset)\n",
    "  PreprocessReviews(dataset)\n",
    "  nullPlaceholders = {}\n",
    "  if exists('placeholders.sav'):\n",
    "    placeholdersFile = open('placeholders.sav','rb')\n",
    "    nullPlaceholders = pickle.load(placeholdersFile)\n",
    "  else:\n",
    "    placeholdersFile = open('placeholders.sav',\"x\")\n",
    "    placeholdersFile = open('placeholders.sav',\"wb\")\n",
    "    nullPlaceholders = getPlaceHolders(dataset)\n",
    "    pickle.dump(nullPlaceholders,placeholdersFile)\n",
    "  replace_null_values(dataset,nullPlaceholders)\n",
    "  Normalization(dataset)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0flIX0HG4XQw",
   "metadata": {
    "id": "0flIX0HG4XQw"
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "432cd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNumericalFeatures(dataset):\n",
    "    return [i for i in dataset if dataset.dtypes[i] != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "oOQ6OWsv4eek",
   "metadata": {
    "id": "oOQ6OWsv4eek"
   },
   "outputs": [],
   "source": [
    "def SelectFeatures(X,Y,numericalFunction,kNumerical,categoricalFunction,kCategorical,numerical_cols,cache_name = 'selectedFeatures.sav'):\n",
    "  if exists(cache_name):\n",
    "    selected_Names = pickle.load(open(cache_name,'rb'))\n",
    "    return X[selected_Names]\n",
    "  else:\n",
    "    numericalFeatures = list(numerical_cols)\n",
    "    categoricalFeatures = [i for i in X.columns.values if not i in numerical_cols]\n",
    "    print(categoricalFeatures)\n",
    "    for i in X:\n",
    "      if X.dtypes[i] == 'object':\n",
    "        categoricalFeatures.append(i)\n",
    "      else:\n",
    "        numericalFeatures.append(i)\n",
    "    numericalSelector = SelectKBest(numericalFunction,k = kNumerical)\n",
    "    categoricalSelector = SelectKBest(categoricalFunction,k = kCategorical)\n",
    "    X_numerical = numericalSelector.fit_transform(X,Y)\n",
    "    X_categorical = categoricalSelector.fit_transform(X,Y)  \n",
    "    new_X = np.concatenate((X_numerical,X_categorical),axis = 1)\n",
    "    selected_Names = list(X.columns.values[numericalSelector.get_support()])\n",
    "    selected_Names = selected_Names + list(X.columns.values[categoricalSelector.get_support()])\n",
    "    cache_file = open(cache_name,'x')\n",
    "    cache_file = open(cache_name,'wb')\n",
    "    pickle.dump(selected_Names,cache_file)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o07xO7DtAnrI",
   "metadata": {
    "id": "o07xO7DtAnrI"
   },
   "source": [
    "# **Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zwXtnyUTLRBA",
   "metadata": {
    "id": "zwXtnyUTLRBA"
   },
   "source": [
    "This section is for hotel_regression only, hotel classification is below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e2ba3",
   "metadata": {
    "id": "122e2ba3"
   },
   "source": [
    "## Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f662980b",
   "metadata": {
    "id": "f662980b"
   },
   "outputs": [],
   "source": [
    "rawReviews = pd.read_csv(\"hotel-regression-dataset.csv\")\n",
    "rawReviews = Preprocessing(rawReviews)\n",
    "Y = rawReviews.loc()[:,\"Reviewer_Score\"]\n",
    "numerical_features = GetNumericalFeatures(rawReviews)\n",
    "rawReviews = EncodeGB(rawReviews.drop('Reviewer_Score',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8868e9d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8868e9d5",
    "outputId": "785c6e54-f9b1-40f3-b2a7-92763305278d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290315 entries, 0 to 290314\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   Additional_Number_of_Scoring                290315 non-null  float64\n",
      " 1   Review_Date                                 290315 non-null  float64\n",
      " 2   Average_Score                               290315 non-null  float64\n",
      " 3   Hotel_Name_0                                290315 non-null  int64  \n",
      " 4   Hotel_Name_1                                290315 non-null  int64  \n",
      " 5   Hotel_Name_2                                290315 non-null  int64  \n",
      " 6   Hotel_Name_3                                290315 non-null  int64  \n",
      " 7   Hotel_Name_4                                290315 non-null  int64  \n",
      " 8   Hotel_Name_5                                290315 non-null  int64  \n",
      " 9   Hotel_Name_6                                290315 non-null  int64  \n",
      " 10  Hotel_Name_7                                290315 non-null  int64  \n",
      " 11  Hotel_Name_8                                290315 non-null  int64  \n",
      " 12  Hotel_Name_9                                290315 non-null  int64  \n",
      " 13  Hotel_Name_10                               290315 non-null  int64  \n",
      " 14  Reviewer_Nationality_0                      290315 non-null  int64  \n",
      " 15  Reviewer_Nationality_1                      290315 non-null  int64  \n",
      " 16  Reviewer_Nationality_2                      290315 non-null  int64  \n",
      " 17  Reviewer_Nationality_3                      290315 non-null  int64  \n",
      " 18  Reviewer_Nationality_4                      290315 non-null  int64  \n",
      " 19  Reviewer_Nationality_5                      290315 non-null  int64  \n",
      " 20  Reviewer_Nationality_6                      290315 non-null  int64  \n",
      " 21  Reviewer_Nationality_7                      290315 non-null  int64  \n",
      " 22  Negative_Review                             290315 non-null  float64\n",
      " 23  Review_Total_Negative_Word_Counts           290315 non-null  float64\n",
      " 24  Total_Number_of_Reviews                     290315 non-null  float64\n",
      " 25  Positive_Review                             290315 non-null  float64\n",
      " 26  Review_Total_Positive_Word_Counts           290315 non-null  float64\n",
      " 27  Total_Number_of_Reviews_Reviewer_Has_Given  290315 non-null  float64\n",
      " 28  days_since_review                           290315 non-null  float64\n",
      " 29  lat                                         290315 non-null  float64\n",
      " 30  lng                                         290315 non-null  float64\n",
      " 31  Review_month                                290315 non-null  float64\n",
      " 32  trip_type                                   290315 non-null  float64\n",
      " 33  duration                                    290315 non-null  float64\n",
      " 34  room_type_0                                 290315 non-null  int64  \n",
      " 35  room_type_1                                 290315 non-null  int64  \n",
      " 36  room_type_2                                 290315 non-null  int64  \n",
      " 37  bed_type                                    290315 non-null  int64  \n",
      " 38  submit                                      290315 non-null  float64\n",
      " 39  Hotel_Address_Austria                       290315 non-null  uint8  \n",
      " 40  Hotel_Address_France                        290315 non-null  uint8  \n",
      " 41  Hotel_Address_Italy                         290315 non-null  uint8  \n",
      " 42  Hotel_Address_Netherlands                   290315 non-null  uint8  \n",
      " 43  Hotel_Address_Spain                         290315 non-null  uint8  \n",
      " 44  Hotel_Address_United Kingdom                290315 non-null  uint8  \n",
      " 45  customer_type_ Couple                       290315 non-null  uint8  \n",
      " 46  customer_type_ Family with older children   290315 non-null  uint8  \n",
      " 47  customer_type_ Family with young children   290315 non-null  uint8  \n",
      " 48  customer_type_ Group                        290315 non-null  uint8  \n",
      " 49  customer_type_ Solo traveler                290315 non-null  uint8  \n",
      " 50  customer_type_ Travelers with friends       290315 non-null  uint8  \n",
      "dtypes: float64(16), int64(23), uint8(12)\n",
      "memory usage: 89.7 MB\n"
     ]
    }
   ],
   "source": [
    "rawReviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f37a2396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "f37a2396",
    "outputId": "1db9086f-2f3f-4e3b-819d-b62ad323af8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name_0</th>\n",
       "      <th>Hotel_Name_1</th>\n",
       "      <th>Hotel_Name_2</th>\n",
       "      <th>Hotel_Name_3</th>\n",
       "      <th>Hotel_Name_4</th>\n",
       "      <th>Hotel_Name_5</th>\n",
       "      <th>Hotel_Name_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Hotel_Address_Italy</th>\n",
       "      <th>Hotel_Address_Netherlands</th>\n",
       "      <th>Hotel_Address_Spain</th>\n",
       "      <th>Hotel_Address_United Kingdom</th>\n",
       "      <th>customer_type_ Couple</th>\n",
       "      <th>customer_type_ Family with older children</th>\n",
       "      <th>customer_type_ Family with young children</th>\n",
       "      <th>customer_type_ Group</th>\n",
       "      <th>customer_type_ Solo traveler</th>\n",
       "      <th>customer_type_ Travelers with friends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300261</td>\n",
       "      <td>0.895890</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.338307</td>\n",
       "      <td>0.326084</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.336815</td>\n",
       "      <td>0.527397</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085416</td>\n",
       "      <td>0.472603</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089519</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Additional_Number_of_Scoring  Review_Date  Average_Score  Hotel_Name_0  \\\n",
       "0                      0.300261     0.895890       0.565217             0   \n",
       "1                      0.338307     0.326084       0.717391             0   \n",
       "2                      0.336815     0.527397       0.630435             0   \n",
       "3                      0.085416     0.472603       0.739130             0   \n",
       "4                      0.089519     0.900000       0.500000             0   \n",
       "\n",
       "   Hotel_Name_1  Hotel_Name_2  Hotel_Name_3  Hotel_Name_4  Hotel_Name_5  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Hotel_Name_6  ...  Hotel_Address_Italy  Hotel_Address_Netherlands  \\\n",
       "0             0  ...                    0                          0   \n",
       "1             0  ...                    0                          0   \n",
       "2             0  ...                    1                          0   \n",
       "3             0  ...                    0                          0   \n",
       "4             0  ...                    0                          0   \n",
       "\n",
       "   Hotel_Address_Spain  Hotel_Address_United Kingdom  customer_type_ Couple   \\\n",
       "0                    0                             1                       0   \n",
       "1                    0                             1                       0   \n",
       "2                    0                             0                       1   \n",
       "3                    0                             0                       0   \n",
       "4                    0                             1                       1   \n",
       "\n",
       "   customer_type_ Family with older children   \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           1   \n",
       "4                                           0   \n",
       "\n",
       "   customer_type_ Family with young children   customer_type_ Group   \\\n",
       "0                                           1                      0   \n",
       "1                                           0                      1   \n",
       "2                                           0                      0   \n",
       "3                                           0                      0   \n",
       "4                                           0                      0   \n",
       "\n",
       "   customer_type_ Solo traveler   customer_type_ Travelers with friends   \n",
       "0                              0                                       0  \n",
       "1                              0                                       0  \n",
       "2                              0                                       0  \n",
       "3                              0                                       0  \n",
       "4                              0                                       0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "770ea63d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "770ea63d",
    "outputId": "f8f4e6b6-8e2e-4cd6-c7a2-ff3ad00c7f2e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Additional_Number_of_Scoring                  0\n",
       "Review_Date                                   0\n",
       "Average_Score                                 0\n",
       "Hotel_Name_0                                  0\n",
       "Hotel_Name_1                                  0\n",
       "Hotel_Name_2                                  0\n",
       "Hotel_Name_3                                  0\n",
       "Hotel_Name_4                                  0\n",
       "Hotel_Name_5                                  0\n",
       "Hotel_Name_6                                  0\n",
       "Hotel_Name_7                                  0\n",
       "Hotel_Name_8                                  0\n",
       "Hotel_Name_9                                  0\n",
       "Hotel_Name_10                                 0\n",
       "Reviewer_Nationality_0                        0\n",
       "Reviewer_Nationality_1                        0\n",
       "Reviewer_Nationality_2                        0\n",
       "Reviewer_Nationality_3                        0\n",
       "Reviewer_Nationality_4                        0\n",
       "Reviewer_Nationality_5                        0\n",
       "Reviewer_Nationality_6                        0\n",
       "Reviewer_Nationality_7                        0\n",
       "Negative_Review                               0\n",
       "Review_Total_Negative_Word_Counts             0\n",
       "Total_Number_of_Reviews                       0\n",
       "Positive_Review                               0\n",
       "Review_Total_Positive_Word_Counts             0\n",
       "Total_Number_of_Reviews_Reviewer_Has_Given    0\n",
       "days_since_review                             0\n",
       "lat                                           0\n",
       "lng                                           0\n",
       "Review_month                                  0\n",
       "trip_type                                     0\n",
       "duration                                      0\n",
       "room_type_0                                   0\n",
       "room_type_1                                   0\n",
       "room_type_2                                   0\n",
       "bed_type                                      0\n",
       "submit                                        0\n",
       "Hotel_Address_Austria                         0\n",
       "Hotel_Address_France                          0\n",
       "Hotel_Address_Italy                           0\n",
       "Hotel_Address_Netherlands                     0\n",
       "Hotel_Address_Spain                           0\n",
       "Hotel_Address_United Kingdom                  0\n",
       "customer_type_ Couple                         0\n",
       "customer_type_ Family with older children     0\n",
       "customer_type_ Family with young children     0\n",
       "customer_type_ Group                          0\n",
       "customer_type_ Solo traveler                  0\n",
       "customer_type_ Travelers with friends         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawReviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-P6cHxHE2qH_",
   "metadata": {
    "id": "-P6cHxHE2qH_"
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "df5dda3b",
   "metadata": {
    "id": "df5dda3b"
   },
   "outputs": [],
   "source": [
    "#rawReviews.loc[((rawReviews[\"bed_type\"] == \"Queen\") | (rawReviews[\"bed_type\"] == \"queen\")),\"bed_type\"] = \"Queen\"           \n",
    "#plt.hist(rawReviews[\"bed_type\"],align='mid',bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1027398",
   "metadata": {
    "id": "b1027398"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.xticks(fontsize=9)\n",
    "#plt.hist(rawReviews[\"customer_type\"],bins = 50,align='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb80c6ce",
   "metadata": {
    "id": "cb80c6ce"
   },
   "outputs": [],
   "source": [
    "#rawReviews['submit'].value_counts()\n",
    "#labels = ['Zeros', 'Ones']\n",
    "\n",
    "#counts = rawReviews['submit'].value_counts()\n",
    "\n",
    "# create the pie chart\n",
    "#fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# add a title\n",
    "#ax.set_title('Number of people Used there cell phone to book')\n",
    "\n",
    "# add a legend\n",
    "#ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "802a2935",
   "metadata": {
    "id": "802a2935"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(25, 6))\n",
    "#plt.hist(rawReviews[\"room_type\"],bins = 30,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa28a1c",
   "metadata": {
    "id": "9aa28a1c"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55c29b",
   "metadata": {
    "id": "1d55c29b"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "22539c2b",
   "metadata": {
    "id": "22539c2b"
   },
   "outputs": [],
   "source": [
    "shape = rawReviews.shape\n",
    "X = SelectFeatures(rawReviews,Y,r_regression,2,f_classif,2,numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465afa6",
   "metadata": {
    "id": "f465afa6"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8bff827c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bff827c",
    "outputId": "873f45ce-0b39-48e5-fe93-508cbc6004f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.34465509 0.3533003  0.35132021 0.35713544 0.35133388]\n",
      "Mean:  0.3515489837798899\n",
      "STD :  0.004047220264100497\n"
     ]
    }
   ],
   "source": [
    "Xtrain,XtestForest,Ytrain,YtestForest = ms.train_test_split(X,Y,test_size=0.2,random_state=12345667)\n",
    "randomModel = RandomForestRegressor()\n",
    "#Scores:  [0.20164883 0.20682618 0.19955316 0.19827348 0.21491949]\n",
    "#Mean:  0.2042442269225707\n",
    "#STD :  0.006083089642406279\n",
    "def displayScores(scores):\n",
    "    print(\"Scores: \",scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"STD : \",scores.std())\n",
    "displayScores(ms.cross_val_score(randomModel,Xtrain,Ytrain,cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ccae2",
   "metadata": {
    "id": "a09ccae2"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b3b07ad2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "b3b07ad2",
    "outputId": "0d09ca3a-caae-4c85-85d6-e331e439dae4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestRegressor(), n_iter=5,\n",
       "                   param_distributions={'n_estimators': range(50, 100, 10)},\n",
       "                   random_state=12345667)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSpace = dict(n_estimators=range(50,100,10))\n",
    "randomModel = ms.RandomizedSearchCV(randomModel,sampleSpace,n_iter = 5,random_state = 12345667)\n",
    "randomModel.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "iOVVP_LK8TDQ",
   "metadata": {
    "id": "iOVVP_LK8TDQ"
   },
   "outputs": [],
   "source": [
    "name = 'random_model.sav'\n",
    "pickle.dump(randomModel, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81723f90",
   "metadata": {
    "id": "81723f90"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e28d552",
   "metadata": {
    "id": "8e28d552"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5f7ed19d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "5f7ed19d",
    "outputId": "5f7ef9dd-5d83-469d-c2ff-4699359f46d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the decision tree regressor and fit the model to the training data\n",
    "treeModel = DecisionTreeRegressor()\n",
    "treeModel.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "uuhLI6rV_bx3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuhLI6rV_bx3",
    "outputId": "d6b70634-f997-46a3-fd69-471e72153db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of pickle treeModel:  0.33432586554208577\n"
     ]
    }
   ],
   "source": [
    "name = 'DecisionTreeRegressor.sav'\n",
    "pickle.dump(treeModel, open(name, 'wb'))\n",
    "loaded_file = pickle.load(open(name, 'rb'))\n",
    "print(\"result of pickle treeModel: \", loaded_file.score(XtestForest, YtestForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501f2de",
   "metadata": {
    "id": "c501f2de"
   },
   "source": [
    "## Multiple Linear Regression (backward elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdb08c",
   "metadata": {
    "id": "3ffdb08c"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ac89380e",
   "metadata": {
    "id": "ac89380e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hotel-regression-dataset.csv\")\n",
    "df = Preprocessing(df)\n",
    "df = EncodeLR(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5f53e953",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f53e953",
    "outputId": "887afd54-bf72-4129-e185-889a0781b246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column index: 1 Column name: Additional_Number_of_Scoring\n",
      "Column index: 2 Column name: Review_Date\n",
      "Column index: 3 Column name: Average_Score\n",
      "Column index: 4 Column name: Reviewer_Nationality\n",
      "Column index: 5 Column name: Negative_Review\n",
      "Column index: 6 Column name: Review_Total_Negative_Word_Counts\n",
      "Column index: 7 Column name: Total_Number_of_Reviews\n",
      "Column index: 8 Column name: Positive_Review\n",
      "Column index: 9 Column name: Review_Total_Positive_Word_Counts\n",
      "Column index: 10 Column name: Total_Number_of_Reviews_Reviewer_Has_Given\n",
      "Column index: 11 Column name: days_since_review\n",
      "Column index: 12 Column name: lat\n",
      "Column index: 13 Column name: lng\n",
      "Column index: 14 Column name: Reviewer_Score\n",
      "Column index: 15 Column name: Review_month\n",
      "Column index: 16 Column name: trip_type\n",
      "Column index: 17 Column name: duration\n",
      "Column index: 18 Column name: room_type\n",
      "Column index: 19 Column name: bed_type\n",
      "Column index: 20 Column name: submit\n",
      "Column index: 21 Column name: Hotel_Address_Austria\n",
      "Column index: 22 Column name: Hotel_Address_France\n",
      "Column index: 23 Column name: Hotel_Address_Italy\n",
      "Column index: 24 Column name: Hotel_Address_Netherlands\n",
      "Column index: 25 Column name: Hotel_Address_Spain\n",
      "Column index: 26 Column name: Hotel_Address_United Kingdom\n",
      "Column index: 27 Column name: customer_type_ Couple \n",
      "Column index: 28 Column name: customer_type_ Family with older children \n",
      "Column index: 29 Column name: customer_type_ Family with young children \n",
      "Column index: 30 Column name: customer_type_ Group \n",
      "Column index: 31 Column name: customer_type_ Solo traveler \n",
      "Column index: 32 Column name: customer_type_ Travelers with friends \n"
     ]
    }
   ],
   "source": [
    "for i, col_name in enumerate(df.columns):\n",
    "    print(\"Column index:\", i+1, \"Column name:\", col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5ef3d804",
   "metadata": {
    "id": "5ef3d804"
   },
   "outputs": [],
   "source": [
    "Y_ = df[\"Reviewer_Score\"]\n",
    "X_ = df.drop(\"Reviewer_Score\",axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d338aa",
   "metadata": {
    "id": "33d338aa"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dff2196",
   "metadata": {
    "id": "5dff2196"
   },
   "source": [
    "Backward elimination is a technique used for feature selection in machine learning.\n",
    "\n",
    "Backward elimination is a backward-stepwise regression technique that starts with a model containing all the features and then iteratively removes the least significant feature one at a time until a stopping criterion is met. The stopping criterion can be based on a statistical significance level, a threshold for the change in model performance, or some other criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc566e1e",
   "metadata": {
    "id": "fc566e1e"
   },
   "source": [
    "* Here are the general steps for performing backward elimination:\n",
    "\n",
    "1-select a significance level to stay in the model (e.g. sl=0.05).\n",
    "\n",
    "2-fill the full model with possible predictors.\n",
    "\n",
    "3-consider the predictor with the highest p-value\n",
    "  if p-value> sl go to step 4 , otherwise go to Finish.\n",
    "  \n",
    "4- Remove the predictor .\n",
    "\n",
    "5- fit the model without this variable.\n",
    "\n",
    "\n",
    "* Note : \n",
    " p-value : is a measure of the evidence against the null hypothesis, and it helps to determine whether the results of a hypothesis test are statistically significant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b6116952",
   "metadata": {
    "id": "b6116952"
   },
   "outputs": [],
   "source": [
    "X_=np.append(arr=np.ones((290315,1)).astype(int),values=X_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "_phKrGyaBQrS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_phKrGyaBQrS",
    "outputId": "8dd05479-2a7a-480d-8b42-145ec0ad425e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Reviewer_Score</td>  <th>  R-squared:         </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   6490.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:25:11</td>     <th>  Log-Likelihood:    </th> <td>1.0056e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>290315</td>      <th>  AIC:               </th> <td>-2.011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>290286</td>      <th>  BIC:               </th> <td>-2.008e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    28</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.189e+10</td> <td> 1.87e+10</td> <td>   -0.635</td> <td> 0.526</td> <td>-4.86e+10</td> <td> 2.48e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0044</td> <td>    0.004</td> <td>    0.999</td> <td> 0.318</td> <td>   -0.004</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  129.9559</td> <td>   11.835</td> <td>   10.981</td> <td> 0.000</td> <td>  106.760</td> <td>  153.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.4747</td> <td>    0.003</td> <td>  168.712</td> <td> 0.000</td> <td>    0.469</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0567</td> <td>    0.002</td> <td>   35.086</td> <td> 0.000</td> <td>    0.053</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.0847</td> <td>    0.001</td> <td> -112.613</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.8572</td> <td>    0.005</td> <td> -176.128</td> <td> 0.000</td> <td>   -0.867</td> <td>   -0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0086</td> <td>    0.005</td> <td>   -1.728</td> <td> 0.084</td> <td>   -0.018</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.1252</td> <td>    0.001</td> <td>  135.342</td> <td> 0.000</td> <td>    0.123</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.5895</td> <td>    0.006</td> <td>   94.471</td> <td> 0.000</td> <td>    0.577</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.0140</td> <td>    0.009</td> <td>    1.498</td> <td> 0.134</td> <td>   -0.004</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  129.9499</td> <td>   11.835</td> <td>   10.981</td> <td> 0.000</td> <td>  106.755</td> <td>  153.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0152</td> <td>    0.018</td> <td>   -0.828</td> <td> 0.408</td> <td>   -0.051</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0013</td> <td>    0.008</td> <td>   -0.169</td> <td> 0.866</td> <td>   -0.016</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0134</td> <td>    0.001</td> <td>  -11.961</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0327</td> <td>    0.001</td> <td>  -31.514</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0170</td> <td>    0.006</td> <td>    2.827</td> <td> 0.005</td> <td>    0.005</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>-5.807e+08</td> <td> 1.65e+09</td> <td>   -0.352</td> <td> 0.725</td> <td>-3.81e+09</td> <td> 2.65e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>-5.534e+08</td> <td>  1.6e+09</td> <td>   -0.345</td> <td> 0.730</td> <td> -3.7e+09</td> <td> 2.59e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.0027</td> <td>    0.001</td> <td>   -4.025</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td> 1.627e+10</td> <td> 2.82e+10</td> <td>    0.576</td> <td> 0.564</td> <td> -3.9e+10</td> <td> 7.16e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>-4.379e+09</td> <td> 9.62e+09</td> <td>   -0.455</td> <td> 0.649</td> <td>-2.32e+10</td> <td> 1.45e+10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>-3.245e+09</td> <td>  6.4e+09</td> <td>   -0.507</td> <td> 0.612</td> <td>-1.58e+10</td> <td> 9.29e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>-3.245e+09</td> <td>  6.4e+09</td> <td>   -0.507</td> <td> 0.612</td> <td>-1.58e+10</td> <td> 9.29e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>-2.111e+09</td> <td> 3.24e+09</td> <td>   -0.652</td> <td> 0.514</td> <td>-8.45e+09</td> <td> 4.23e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>-9.771e+08</td> <td> 1.09e+09</td> <td>   -0.895</td> <td> 0.371</td> <td>-3.12e+09</td> <td> 1.16e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td> 1.571e+08</td> <td> 3.62e+09</td> <td>    0.043</td> <td> 0.965</td> <td>-6.93e+09</td> <td> 7.25e+09</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40053.915</td> <th>  Durbin-Watson:     </th> <td>   2.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>76033.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.882</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.783</td>   <th>  Cond. No.          </th> <td>1.16e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.84e-26. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         Reviewer_Score   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.385\n",
       "Method:                 Least Squares   F-statistic:                     6490.\n",
       "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        03:25:11   Log-Likelihood:             1.0056e+05\n",
       "No. Observations:              290315   AIC:                        -2.011e+05\n",
       "Df Residuals:                  290286   BIC:                        -2.008e+05\n",
       "Df Model:                          28                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.189e+10   1.87e+10     -0.635      0.526   -4.86e+10    2.48e+10\n",
       "x1             0.0044      0.004      0.999      0.318      -0.004       0.013\n",
       "x2           129.9559     11.835     10.981      0.000     106.760     153.151\n",
       "x3             0.4747      0.003    168.712      0.000       0.469       0.480\n",
       "x4             0.0567      0.002     35.086      0.000       0.053       0.060\n",
       "x5            -0.0847      0.001   -112.613      0.000      -0.086      -0.083\n",
       "x6            -0.8572      0.005   -176.128      0.000      -0.867      -0.848\n",
       "x7            -0.0086      0.005     -1.728      0.084      -0.018       0.001\n",
       "x8             0.1252      0.001    135.342      0.000       0.123       0.127\n",
       "x9             0.5895      0.006     94.471      0.000       0.577       0.602\n",
       "x10            0.0140      0.009      1.498      0.134      -0.004       0.032\n",
       "x11          129.9499     11.835     10.981      0.000     106.755     153.145\n",
       "x12           -0.0152      0.018     -0.828      0.408      -0.051       0.021\n",
       "x13           -0.0013      0.008     -0.169      0.866      -0.016       0.013\n",
       "x14           -0.0134      0.001    -11.961      0.000      -0.016      -0.011\n",
       "x15           -0.0327      0.001    -31.514      0.000      -0.035      -0.031\n",
       "x16            0.0170      0.006      2.827      0.005       0.005       0.029\n",
       "x17        -5.807e+08   1.65e+09     -0.352      0.725   -3.81e+09    2.65e+09\n",
       "x18        -5.534e+08    1.6e+09     -0.345      0.730    -3.7e+09    2.59e+09\n",
       "x19           -0.0027      0.001     -4.025      0.000      -0.004      -0.001\n",
       "x20         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x21         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x22         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x23         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x24         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x25         1.627e+10   2.82e+10      0.576      0.564    -3.9e+10    7.16e+10\n",
       "x26        -4.379e+09   9.62e+09     -0.455      0.649   -2.32e+10    1.45e+10\n",
       "x27        -3.245e+09    6.4e+09     -0.507      0.612   -1.58e+10    9.29e+09\n",
       "x28        -3.245e+09    6.4e+09     -0.507      0.612   -1.58e+10    9.29e+09\n",
       "x29        -2.111e+09   3.24e+09     -0.652      0.514   -8.45e+09    4.23e+09\n",
       "x30        -9.771e+08   1.09e+09     -0.895      0.371   -3.12e+09    1.16e+09\n",
       "x31         1.571e+08   3.62e+09      0.043      0.965   -6.93e+09    7.25e+09\n",
       "==============================================================================\n",
       "Omnibus:                    40053.915   Durbin-Watson:                   2.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76033.328\n",
       "Skew:                          -0.882   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.783   Cond. No.                     1.16e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.84e-26. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=X_[: , [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]]\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9kmbCICJBQ-4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "id": "9kmbCICJBQ-4",
    "outputId": "70a7e41e-fba9-4f22-95ac-e90850eb6155"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Reviewer_Score</td>  <th>  R-squared:         </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   8654.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:25:12</td>     <th>  Log-Likelihood:    </th> <td>1.0056e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>290315</td>      <th>  AIC:               </th> <td>-2.011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>290293</td>      <th>  BIC:               </th> <td>-2.008e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-2.925e+09</td> <td> 3.46e+09</td> <td>   -0.845</td> <td> 0.398</td> <td>-9.71e+09</td> <td> 3.86e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  129.2065</td> <td>   11.823</td> <td>   10.928</td> <td> 0.000</td> <td>  106.033</td> <td>  152.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4764</td> <td>    0.003</td> <td>  173.246</td> <td> 0.000</td> <td>    0.471</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0559</td> <td>    0.002</td> <td>   36.004</td> <td> 0.000</td> <td>    0.053</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0847</td> <td>    0.001</td> <td> -112.670</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.8573</td> <td>    0.005</td> <td> -176.178</td> <td> 0.000</td> <td>   -0.867</td> <td>   -0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1253</td> <td>    0.001</td> <td>  135.519</td> <td> 0.000</td> <td>    0.123</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5898</td> <td>    0.006</td> <td>   94.580</td> <td> 0.000</td> <td>    0.578</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  129.2005</td> <td>   11.823</td> <td>   10.928</td> <td> 0.000</td> <td>  106.028</td> <td>  152.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0134</td> <td>    0.001</td> <td>  -11.953</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0327</td> <td>    0.001</td> <td>  -31.611</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0188</td> <td>    0.006</td> <td>    3.180</td> <td> 0.001</td> <td>    0.007</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td> 2.925e+09</td> <td> 3.46e+09</td> <td>    0.845</td> <td> 0.398</td> <td>-3.86e+09</td> <td> 9.71e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0028</td> <td>    0.001</td> <td>   -4.179</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0033</td> <td>    0.001</td> <td>    2.632</td> <td> 0.008</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0051</td> <td>    0.001</td> <td>   -4.000</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0079</td> <td>    0.001</td> <td>    7.645</td> <td> 0.000</td> <td>    0.006</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td> 2.925e+09</td> <td> 3.46e+09</td> <td>    0.845</td> <td> 0.398</td> <td>-3.86e+09</td> <td> 9.71e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -0.0080</td> <td>    0.002</td> <td>   -4.635</td> <td> 0.000</td> <td>   -0.011</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>-2.925e+09</td> <td> 3.46e+09</td> <td>   -0.845</td> <td> 0.398</td> <td>-9.71e+09</td> <td> 3.86e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td> -5.85e+09</td> <td> 6.92e+09</td> <td>   -0.845</td> <td> 0.398</td> <td>-1.94e+10</td> <td> 7.72e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>-8.775e+09</td> <td> 1.04e+10</td> <td>   -0.845</td> <td> 0.398</td> <td>-2.91e+10</td> <td> 1.16e+10</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40168.218</td> <th>  Durbin-Watson:     </th> <td>   2.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>76334.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.883</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.786</td>   <th>  Cond. No.          </th> <td>1.07e+14</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.44e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         Reviewer_Score   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.385\n",
       "Method:                 Least Squares   F-statistic:                     8654.\n",
       "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        03:25:12   Log-Likelihood:             1.0056e+05\n",
       "No. Observations:              290315   AIC:                        -2.011e+05\n",
       "Df Residuals:                  290293   BIC:                        -2.008e+05\n",
       "Df Model:                          21                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -2.925e+09   3.46e+09     -0.845      0.398   -9.71e+09    3.86e+09\n",
       "x1           129.2065     11.823     10.928      0.000     106.033     152.379\n",
       "x2             0.4764      0.003    173.246      0.000       0.471       0.482\n",
       "x3             0.0559      0.002     36.004      0.000       0.053       0.059\n",
       "x4            -0.0847      0.001   -112.670      0.000      -0.086      -0.083\n",
       "x5            -0.8573      0.005   -176.178      0.000      -0.867      -0.848\n",
       "x6             0.1253      0.001    135.519      0.000       0.123       0.127\n",
       "x7             0.5898      0.006     94.580      0.000       0.578       0.602\n",
       "x8           129.2005     11.823     10.928      0.000     106.028     152.373\n",
       "x9            -0.0134      0.001    -11.953      0.000      -0.016      -0.011\n",
       "x10           -0.0327      0.001    -31.611      0.000      -0.035      -0.031\n",
       "x11            0.0188      0.006      3.180      0.001       0.007       0.030\n",
       "x12         2.925e+09   3.46e+09      0.845      0.398   -3.86e+09    9.71e+09\n",
       "x13           -0.0028      0.001     -4.179      0.000      -0.004      -0.001\n",
       "x14            0.0033      0.001      2.632      0.008       0.001       0.006\n",
       "x15           -0.0051      0.001     -4.000      0.000      -0.008      -0.003\n",
       "x16            0.0079      0.001      7.645      0.000       0.006       0.010\n",
       "x17         2.925e+09   3.46e+09      0.845      0.398   -3.86e+09    9.71e+09\n",
       "x18           -0.0080      0.002     -4.635      0.000      -0.011      -0.005\n",
       "x19        -2.925e+09   3.46e+09     -0.845      0.398   -9.71e+09    3.86e+09\n",
       "x20         -5.85e+09   6.92e+09     -0.845      0.398   -1.94e+10    7.72e+09\n",
       "x21        -8.775e+09   1.04e+10     -0.845      0.398   -2.91e+10    1.16e+10\n",
       "==============================================================================\n",
       "Omnibus:                    40168.218   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76334.890\n",
       "Skew:                          -0.883   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.786   Cond. No.                     1.07e+14\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.44e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=X_[: , [0,2,3,4,5,6,8,9,11,14,15,16,18,19,20,22,23,26,28,29,30,31]]\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "K-koTR0_BRLV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "id": "K-koTR0_BRLV",
    "outputId": "2d46dfd8-8718-450d-87df-434f305ed678"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Reviewer_Score</td>  <th>  R-squared:         </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   9565.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:25:12</td>     <th>  Log-Likelihood:    </th> <td>1.0056e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>290315</td>      <th>  AIC:               </th> <td>-2.011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>290295</td>      <th>  BIC:               </th> <td>-2.009e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -128.3256</td> <td>   11.799</td> <td>  -10.876</td> <td> 0.000</td> <td> -151.452</td> <td> -105.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  128.7425</td> <td>   11.799</td> <td>   10.911</td> <td> 0.000</td> <td>  105.617</td> <td>  151.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4764</td> <td>    0.003</td> <td>  173.248</td> <td> 0.000</td> <td>    0.471</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0558</td> <td>    0.002</td> <td>   36.001</td> <td> 0.000</td> <td>    0.053</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0847</td> <td>    0.001</td> <td> -112.673</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.8573</td> <td>    0.005</td> <td> -176.179</td> <td> 0.000</td> <td>   -0.867</td> <td>   -0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1253</td> <td>    0.001</td> <td>  135.524</td> <td> 0.000</td> <td>    0.123</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5898</td> <td>    0.006</td> <td>   94.584</td> <td> 0.000</td> <td>    0.578</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  128.7366</td> <td>   11.799</td> <td>   10.911</td> <td> 0.000</td> <td>  105.611</td> <td>  151.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0134</td> <td>    0.001</td> <td>  -11.979</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0327</td> <td>    0.001</td> <td>  -31.951</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0190</td> <td>    0.006</td> <td>    3.204</td> <td> 0.001</td> <td>    0.007</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0011</td> <td>    0.000</td> <td>   -3.308</td> <td> 0.001</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.0028</td> <td>    0.001</td> <td>   -4.174</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0033</td> <td>    0.001</td> <td>    2.630</td> <td> 0.009</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.0051</td> <td>    0.001</td> <td>   -3.992</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0079</td> <td>    0.001</td> <td>    7.633</td> <td> 0.000</td> <td>    0.006</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -0.0071</td> <td>    0.001</td> <td>   -6.892</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0100</td> <td>    0.001</td> <td>    9.502</td> <td> 0.000</td> <td>    0.008</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    0.0176</td> <td>    0.005</td> <td>    3.488</td> <td> 0.000</td> <td>    0.008</td> <td>    0.028</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40127.096</td> <th>  Durbin-Watson:     </th> <td>   2.002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>76239.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.883</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.785</td>   <th>  Cond. No.          </th> <td>1.51e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         Reviewer_Score   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.385\n",
       "Method:                 Least Squares   F-statistic:                     9565.\n",
       "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        03:25:12   Log-Likelihood:             1.0056e+05\n",
       "No. Observations:              290315   AIC:                        -2.011e+05\n",
       "Df Residuals:                  290295   BIC:                        -2.009e+05\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -128.3256     11.799    -10.876      0.000    -151.452    -105.199\n",
       "x1           128.7425     11.799     10.911      0.000     105.617     151.868\n",
       "x2             0.4764      0.003    173.248      0.000       0.471       0.482\n",
       "x3             0.0558      0.002     36.001      0.000       0.053       0.059\n",
       "x4            -0.0847      0.001   -112.673      0.000      -0.086      -0.083\n",
       "x5            -0.8573      0.005   -176.179      0.000      -0.867      -0.848\n",
       "x6             0.1253      0.001    135.524      0.000       0.123       0.127\n",
       "x7             0.5898      0.006     94.584      0.000       0.578       0.602\n",
       "x8           128.7366     11.799     10.911      0.000     105.611     151.862\n",
       "x9            -0.0134      0.001    -11.979      0.000      -0.016      -0.011\n",
       "x10           -0.0327      0.001    -31.951      0.000      -0.035      -0.031\n",
       "x11            0.0190      0.006      3.204      0.001       0.007       0.031\n",
       "x12           -0.0011      0.000     -3.308      0.001      -0.002      -0.000\n",
       "x13           -0.0028      0.001     -4.174      0.000      -0.004      -0.001\n",
       "x14            0.0033      0.001      2.630      0.009       0.001       0.006\n",
       "x15           -0.0051      0.001     -3.992      0.000      -0.008      -0.003\n",
       "x16            0.0079      0.001      7.633      0.000       0.006       0.010\n",
       "x17           -0.0071      0.001     -6.892      0.000      -0.009      -0.005\n",
       "x18            0.0100      0.001      9.502      0.000       0.008       0.012\n",
       "x19            0.0176      0.005      3.488      0.000       0.008       0.028\n",
       "==============================================================================\n",
       "Omnibus:                    40127.096   Durbin-Watson:                   2.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76239.686\n",
       "Skew:                          -0.883   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.785   Cond. No.                     1.51e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=X_[: , [0,2,3,4,5,6,8,9,11,14,15,16,18,19,20,22,23,28,29,31]]\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "qo5S1bNiBa_b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "qo5S1bNiBa_b",
    "outputId": "6f455976-30de-4d93-a3fd-dd3e7a041197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Reviewer_Score</td>  <th>  R-squared:         </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.010e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:25:12</td>     <th>  Log-Likelihood:    </th> <td>1.0056e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>290315</td>      <th>  AIC:               </th> <td>-2.011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>290296</td>      <th>  BIC:               </th> <td>-2.009e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -128.1720</td> <td>   11.800</td> <td>  -10.862</td> <td> 0.000</td> <td> -151.299</td> <td> -105.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  128.5875</td> <td>   11.799</td> <td>   10.898</td> <td> 0.000</td> <td>  105.461</td> <td>  151.713</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4771</td> <td>    0.003</td> <td>  173.936</td> <td> 0.000</td> <td>    0.472</td> <td>    0.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0565</td> <td>    0.002</td> <td>   36.694</td> <td> 0.000</td> <td>    0.053</td> <td>    0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0847</td> <td>    0.001</td> <td> -112.674</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.8572</td> <td>    0.005</td> <td> -176.156</td> <td> 0.000</td> <td>   -0.867</td> <td>   -0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1253</td> <td>    0.001</td> <td>  135.546</td> <td> 0.000</td> <td>    0.123</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5897</td> <td>    0.006</td> <td>   94.574</td> <td> 0.000</td> <td>    0.577</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  128.5817</td> <td>   11.799</td> <td>   10.898</td> <td> 0.000</td> <td>  105.456</td> <td>  151.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0134</td> <td>    0.001</td> <td>  -11.940</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0344</td> <td>    0.001</td> <td>  -38.323</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0196</td> <td>    0.006</td> <td>    3.318</td> <td> 0.001</td> <td>    0.008</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0027</td> <td>    0.001</td> <td>   -4.098</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0033</td> <td>    0.001</td> <td>    2.687</td> <td> 0.007</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0050</td> <td>    0.001</td> <td>   -3.916</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.0080</td> <td>    0.001</td> <td>    7.716</td> <td> 0.000</td> <td>    0.006</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -0.0074</td> <td>    0.001</td> <td>   -7.230</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    0.0087</td> <td>    0.001</td> <td>    8.912</td> <td> 0.000</td> <td>    0.007</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    0.0142</td> <td>    0.005</td> <td>    2.865</td> <td> 0.004</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40137.462</td> <th>  Durbin-Watson:     </th> <td>   2.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>76268.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.883</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.786</td>   <th>  Cond. No.          </th> <td>1.28e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.28e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         Reviewer_Score   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.385\n",
       "Method:                 Least Squares   F-statistic:                 1.010e+04\n",
       "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        03:25:12   Log-Likelihood:             1.0056e+05\n",
       "No. Observations:              290315   AIC:                        -2.011e+05\n",
       "Df Residuals:                  290296   BIC:                        -2.009e+05\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -128.1720     11.800    -10.862      0.000    -151.299    -105.045\n",
       "x1           128.5875     11.799     10.898      0.000     105.461     151.713\n",
       "x2             0.4771      0.003    173.936      0.000       0.472       0.482\n",
       "x3             0.0565      0.002     36.694      0.000       0.053       0.059\n",
       "x4            -0.0847      0.001   -112.674      0.000      -0.086      -0.083\n",
       "x5            -0.8572      0.005   -176.156      0.000      -0.867      -0.848\n",
       "x6             0.1253      0.001    135.546      0.000       0.123       0.127\n",
       "x7             0.5897      0.006     94.574      0.000       0.577       0.602\n",
       "x8           128.5817     11.799     10.898      0.000     105.456     151.707\n",
       "x9            -0.0134      0.001    -11.940      0.000      -0.016      -0.011\n",
       "x10           -0.0344      0.001    -38.323      0.000      -0.036      -0.033\n",
       "x11            0.0196      0.006      3.318      0.001       0.008       0.031\n",
       "x12           -0.0027      0.001     -4.098      0.000      -0.004      -0.001\n",
       "x13            0.0033      0.001      2.687      0.007       0.001       0.006\n",
       "x14           -0.0050      0.001     -3.916      0.000      -0.007      -0.002\n",
       "x15            0.0080      0.001      7.716      0.000       0.006       0.010\n",
       "x16           -0.0074      0.001     -7.230      0.000      -0.009      -0.005\n",
       "x17            0.0087      0.001      8.912      0.000       0.007       0.011\n",
       "x18            0.0142      0.005      2.865      0.004       0.004       0.024\n",
       "==============================================================================\n",
       "Omnibus:                    40137.462   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76268.734\n",
       "Skew:                          -0.883   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.786   Cond. No.                     1.28e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.28e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=X_[: , [0,2,3,4,5,6,8,9,11,14,15,16,19,20,22,23,28,29,31]]\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6-hwgvuOBfaG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "6-hwgvuOBfaG",
    "outputId": "ffd3215f-45fe-4e08-b217-03c2aa30c1fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Reviewer_Score</td>  <th>  R-squared:         </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.385</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.211e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>03:25:12</td>     <th>  Log-Likelihood:    </th> <td>1.0054e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>290315</td>      <th>  AIC:               </th> <td>-2.011e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>290299</td>      <th>  BIC:               </th> <td>-2.009e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -126.6482</td> <td>   11.793</td> <td>  -10.739</td> <td> 0.000</td> <td> -149.762</td> <td> -103.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  127.0651</td> <td>   11.793</td> <td>   10.775</td> <td> 0.000</td> <td>  103.952</td> <td>  150.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4776</td> <td>    0.003</td> <td>  174.656</td> <td> 0.000</td> <td>    0.472</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0542</td> <td>    0.001</td> <td>   37.467</td> <td> 0.000</td> <td>    0.051</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.0846</td> <td>    0.001</td> <td> -112.674</td> <td> 0.000</td> <td>   -0.086</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.8569</td> <td>    0.005</td> <td> -176.111</td> <td> 0.000</td> <td>   -0.866</td> <td>   -0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1253</td> <td>    0.001</td> <td>  135.570</td> <td> 0.000</td> <td>    0.124</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5908</td> <td>    0.006</td> <td>   94.857</td> <td> 0.000</td> <td>    0.579</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  127.0592</td> <td>   11.793</td> <td>   10.775</td> <td> 0.000</td> <td>  103.946</td> <td>  150.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0134</td> <td>    0.001</td> <td>  -11.903</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0346</td> <td>    0.001</td> <td>  -38.594</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0027</td> <td>    0.001</td> <td>   -4.005</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.0057</td> <td>    0.001</td> <td>   -4.503</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0078</td> <td>    0.001</td> <td>    7.601</td> <td> 0.000</td> <td>    0.006</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.0074</td> <td>    0.001</td> <td>   -7.188</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.0086</td> <td>    0.001</td> <td>    8.853</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>40136.845</td> <th>  Durbin-Watson:     </th> <td>   2.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>76262.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.883</td>   <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.785</td>   <th>  Cond. No.          </th> <td>1.27e+05</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.27e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         Reviewer_Score   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.385\n",
       "Method:                 Least Squares   F-statistic:                 1.211e+04\n",
       "Date:                Thu, 25 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        03:25:12   Log-Likelihood:             1.0054e+05\n",
       "No. Observations:              290315   AIC:                        -2.011e+05\n",
       "Df Residuals:                  290299   BIC:                        -2.009e+05\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -126.6482     11.793    -10.739      0.000    -149.762    -103.534\n",
       "x1           127.0651     11.793     10.775      0.000     103.952     150.178\n",
       "x2             0.4776      0.003    174.656      0.000       0.472       0.483\n",
       "x3             0.0542      0.001     37.467      0.000       0.051       0.057\n",
       "x4            -0.0846      0.001   -112.674      0.000      -0.086      -0.083\n",
       "x5            -0.8569      0.005   -176.111      0.000      -0.866      -0.847\n",
       "x6             0.1253      0.001    135.570      0.000       0.124       0.127\n",
       "x7             0.5908      0.006     94.857      0.000       0.579       0.603\n",
       "x8           127.0592     11.793     10.775      0.000     103.946     150.172\n",
       "x9            -0.0134      0.001    -11.903      0.000      -0.016      -0.011\n",
       "x10           -0.0346      0.001    -38.594      0.000      -0.036      -0.033\n",
       "x11           -0.0027      0.001     -4.005      0.000      -0.004      -0.001\n",
       "x12           -0.0057      0.001     -4.503      0.000      -0.008      -0.003\n",
       "x13            0.0078      0.001      7.601      0.000       0.006       0.010\n",
       "x14           -0.0074      0.001     -7.188      0.000      -0.009      -0.005\n",
       "x15            0.0086      0.001      8.853      0.000       0.007       0.010\n",
       "==============================================================================\n",
       "Omnibus:                    40136.845   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76262.273\n",
       "Skew:                          -0.883   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.785   Cond. No.                     1.27e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.27e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=X_[: , [0,2,3,4,5,6,8,9,11,14,15,19,22,23,28,29]]\n",
    "regressor_OLS = sm.OLS(endog=Y, exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "db40d675",
   "metadata": {
    "id": "db40d675"
   },
   "outputs": [],
   "source": [
    "# Define the features and target variables\n",
    "X_ = X_[: , [0,2,3,4,5,6,8,9,11,14,15,19,22,23,28,29]]\n",
    "X_train , XtestLinear, y_train, YtestLinear = ms.train_test_split(X_,Y,test_size = 0.2,random_state = 12345667)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QpiBDbhlg3n7",
   "metadata": {
    "id": "QpiBDbhlg3n7"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "g8H-iVwpgpvu",
   "metadata": {
    "id": "g8H-iVwpgpvu"
   },
   "outputs": [],
   "source": [
    "linearModel = LinearRegression()\n",
    "def displayScores(scores):\n",
    "    print(\"Scores: \",scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"STD : \",scores.std())\n",
    "#displayScores(ms.cross_val_score(linearModel,X_train,y_train,cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969e56c",
   "metadata": {
    "id": "e969e56c"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0f3174a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "0f3174a2",
    "outputId": "6c543a9e-73bc-4cba-e1f4-fd3c3939583a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the linear regression model to the training data\n",
    "linearModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9J6hvzly_nc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J6hvzly_nc5",
    "outputId": "8a415913-f229-4331-81c4-57298ff880b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of pickle linear_Model:  0.38595523893330386\n"
     ]
    }
   ],
   "source": [
    "name = 'linear_Model.sav'\n",
    "pickle.dump(linearModel, open(name, 'wb'))\n",
    "loaded_file = pickle.load(open(name, 'rb'))\n",
    "print(\"result of pickle linear_Model: \", loaded_file.score(XtestLinear, YtestLinear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5d92c",
   "metadata": {
    "id": "a3a5d92c"
   },
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7Xi0klr3hBl1",
   "metadata": {
    "id": "7Xi0klr3hBl1"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "kV606RHghBl1",
   "metadata": {
    "id": "kV606RHghBl1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.37539778 0.37396701 0.37438906 0.37354596 0.3725234 ]\n",
      "Mean:  0.37396464187587963\n",
      "STD :  0.0009472569448052174\n"
     ]
    }
   ],
   "source": [
    "x_train, XtestPolynomial, y_train, YtestPolynomial = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(x_train)\n",
    "polyModel = LinearRegression()\n",
    "def displayScores(scores):\n",
    "    print(\"Scores: \",scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"STD : \",scores.std())\n",
    "displayScores(ms.cross_val_score(polyModel,X_poly,y_train,cv = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703849da",
   "metadata": {
    "id": "703849da"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d1b399f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "d1b399f0",
    "outputId": "1cb2f3f2-ac7e-4859-e49b-b12332cc15aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtestPolynomial = poly.fit_transform(XtestPolynomial)\n",
    "polyModel.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8NFRsz_r_4x8",
   "metadata": {
    "id": "8NFRsz_r_4x8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of pickle Polynomial Regression:  0.3699426444971854\n"
     ]
    }
   ],
   "source": [
    "name = 'Polynomial Regression.sav'\n",
    "pickle.dump(polyModel, open(name, 'wb'))\n",
    "loaded_file = pickle.load(open(name, 'rb'))\n",
    "print(\"result of pickle Polynomial Regression: \", loaded_file.score(XtestPolynomial, YtestPolynomial))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2905b8",
   "metadata": {
    "id": "cc2905b8"
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb3013e",
   "metadata": {
    "id": "8fb3013e"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b0a4ee6d",
   "metadata": {
    "id": "b0a4ee6d"
   },
   "outputs": [],
   "source": [
    "X_train, XtestGradient, y_train , YtestGradient = ms.train_test_split(X,Y,test_size = 0.2,random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bdc64027",
   "metadata": {
    "id": "bdc64027"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientModel = GradientBoostingRegressor()\n",
    "gradientModel.fit(X_train,y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "Kn-0rtZcFWNC",
   "metadata": {
    "id": "Kn-0rtZcFWNC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of pickle GradientBoostingRegressor:  0.3746526224950547\n"
     ]
    }
   ],
   "source": [
    "name = 'GradientBoostingRegressor.sav'\n",
    "pickle.dump(gradientModel, open(name, 'wb'))\n",
    "loaded_file = pickle.load(open(name, 'rb'))\n",
    "print(\"result of pickle GradientBoostingRegressor: \", loaded_file.score(XtestGradient, YtestGradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lt26DAuXAeH7",
   "metadata": {
    "id": "Lt26DAuXAeH7"
   },
   "source": [
    "# **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A158gWsMAzrE",
   "metadata": {
    "id": "A158gWsMAzrE"
   },
   "source": [
    "## **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1de3958e",
   "metadata": {
    "id": "1de3958e"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hotel-classification-dataset.csv\")\n",
    "YEncoder = pp.OrdinalEncoder()\n",
    "Y = YEncoder.fit_transform(df['Reviewer_Score'].to_numpy().reshape(-1,1))\n",
    "pickle.dump(YEncoder,open('classificationEncoder.sav','wb'))\n",
    "df = Preprocessing(df.drop('Reviewer_Score',axis = 1))\n",
    "numerical_features = GetNumericalFeatures(df)\n",
    "df = EncodeGB(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5IjPJ_ZglwIw",
   "metadata": {
    "id": "5IjPJ_ZglwIw"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LlF-QUO2lwIx",
   "metadata": {
    "id": "LlF-QUO2lwIx"
   },
   "source": [
    "Use ChiSquared, Mutual Info, Kendalltau, and ANOVA to select both numerical and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DUVVsp-mlwIx",
   "metadata": {
    "id": "DUVVsp-mlwIx"
   },
   "source": [
    "### Kendall for non-linear numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cIcqvJV6lwIx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "cIcqvJV6lwIx",
    "outputId": "c1120915-a5c8-4612-e16d-f2a99f58072a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional_Number_of_Scoring: \n",
      "KendalltauResult(correlation=0.040095724066043475, pvalue=1.4996286106216534e-159)\n",
      "Review_Date: \n",
      "KendalltauResult(correlation=0.0001567144325390061, pvalue=0.9161748595851048)\n",
      "Average_Score: \n",
      "KendalltauResult(correlation=-0.2791900226531388, pvalue=0.0)\n",
      "Negative_Review: \n",
      "KendalltauResult(correlation=0.3461447405894426, pvalue=0.0)\n",
      "Review_Total_Negative_Word_Counts: \n",
      "KendalltauResult(correlation=0.3344590261157566, pvalue=0.0)\n",
      "Total_Number_of_Reviews: \n",
      "KendalltauResult(correlation=0.058523166418717326, pvalue=0.0)\n",
      "Positive_Review: \n",
      "KendalltauResult(correlation=-0.25380453519047586, pvalue=0.0)\n",
      "Review_Total_Positive_Word_Counts: \n",
      "KendalltauResult(correlation=-0.24226612449779988, pvalue=0.0)\n",
      "Total_Number_of_Reviews_Reviewer_Has_Given: \n",
      "KendalltauResult(correlation=0.008022634698618917, pvalue=3.2220944451169506e-07)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\scipy\\stats\\stats.py:4812: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_since_review: \n",
      "KendalltauResult(correlation=-0.0001567144325390061, pvalue=0.9161748595851048)\n",
      "lat: \n",
      "KendalltauResult(correlation=0.019290170309711568, pvalue=2.2076856353640886e-38)\n",
      "lng: \n",
      "KendalltauResult(correlation=-0.05293217229906505, pvalue=8.815018074347621e-277)\n",
      "Review_month: \n",
      "KendalltauResult(correlation=0.024272013977455716, pvalue=2.4041013112379912e-55)\n",
      "trip_type: \n",
      "KendalltauResult(correlation=0.10156162850411934, pvalue=0.0)\n",
      "duration: \n",
      "KendalltauResult(correlation=0.008989830114743864, pvalue=5.4719329135221515e-08)\n",
      "submit: \n",
      "KendalltauResult(correlation=-0.02022897487065432, pvalue=1.2173956146965164e-28)\n"
     ]
    }
   ],
   "source": [
    "numericalFeatures =  numerical_features\n",
    "for i in numericalFeatures:\n",
    "    kendallscore = kendalltau(df[i],Y)\n",
    "    print(i + \": \")\n",
    "    print(kendallscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4zAHanaAlwIy",
   "metadata": {
    "id": "4zAHanaAlwIy"
   },
   "source": [
    "### Anova for linear numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "jjzxPr4llwIy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjzxPr4llwIy",
    "outputId": "e1e2354d-8437-4d5c-cd4e-a1f06ed2be25"
   },
   "outputs": [],
   "source": [
    "#for i in numericalFeatures:\n",
    "#    anovaScore = f_classif(df[i].to_numpy().reshape((-1,1)),Y.to_numpy().reshape((-1,1)))\n",
    "#    print(i + \": \")\n",
    "#    print(anovaScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ErNjKSXllwIy",
   "metadata": {
    "id": "ErNjKSXllwIy"
   },
   "source": [
    "### ChiSquare for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "weJdyz67lwIy",
   "metadata": {
    "id": "weJdyz67lwIy"
   },
   "outputs": [],
   "source": [
    "categoricalFeatures = [\"room_type\",\"bed_type\",\"customer_type\",\"duration\",\"submit\",\"Hotel_Address\",\"Hotel_Name\",\"Reviewer_Nationality\",\"Negative_Review\",\"Positive_Review\"]\n",
    "#for i in categoricalFeatures:\n",
    "    #chi = chi2(df[i],df[\"Reviewer_Score\"])\n",
    "    #print(i + \": \")\n",
    "    #print(chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qpa_Xh3alwIy",
   "metadata": {
    "id": "qpa_Xh3alwIy"
   },
   "source": [
    "### Mutual Information for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lq0L73JDlwIy",
   "metadata": {
    "id": "lq0L73JDlwIy"
   },
   "outputs": [],
   "source": [
    "#for i in categoricalFeatures:\n",
    " #   mutualScore = mutual_info_classif(df[i].to_numpy().reshape((-1,1)),df[\"Reviewer_Score\"].to_numpy().reshape((-1,1)))\n",
    "  #  print(i + \": \")\n",
    "   # print(mutualScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzPsOv-_lwIy",
   "metadata": {
    "id": "wzPsOv-_lwIy"
   },
   "source": [
    "### Select common features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "TvFdViEnlwIy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "TvFdViEnlwIy",
    "outputId": "dab3aaf0-7a28-479f-c2d3-924ffa87ffc0"
   },
   "outputs": [],
   "source": [
    "X = SelectFeatures(df,Y,r_regression,3,f_classif,2,numerical_features,'classifSelectedFeatures.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FAIyHij_J5Cd",
   "metadata": {
    "id": "FAIyHij_J5Cd"
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "x__UseYyJ_eb",
   "metadata": {
    "id": "x__UseYyJ_eb"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size= 0.2,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "q-sVsRLB3Ujo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-sVsRLB3Ujo",
    "outputId": "372df5b1-9911-4c12-8e3d-6a464e92edb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OWk8HVOUh08u",
   "metadata": {
    "id": "OWk8HVOUh08u"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "PsMrEAhNhzyS",
   "metadata": {
    "id": "PsMrEAhNhzyS"
   },
   "outputs": [],
   "source": [
    "\n",
    "classification_model = {\n",
    "    'DT': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "           'min_samples_split' : [5,10,15,20], #min samples to split a node\n",
    "           'criterion' : ['gini','entropy'], #Function to measure the quality of a split\n",
    "           'splitter' : ['best','random'],\n",
    "           'min_samples_leaf' : [1,2,3,4,5],\n",
    "           'max_features' : [1,50]\n",
    "        }\n",
    "    },\n",
    "    'GBC': {\n",
    "        'model' : GradientBoostingClassifier(),\n",
    "        'params' : {\n",
    "            \"loss\":[\"log_loss\", \"deviance\", \"exponential\"],\n",
    "            \"learning_rate\":[0.1,0.01,0.001],\n",
    "            \"n_estimators\":[10,100,200],}\n",
    "         },\n",
    "    'logistic':{\n",
    "        'model' : LogisticRegression(),\n",
    "        'params': {\n",
    "            'penalty': ['l1', 'l2'],#determines the type of regularization \n",
    "            'C': [0.1, 1, 10] #the inverse of the regularization strength\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ndN1_4iF23yp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndN1_4iF23yp",
    "outputId": "fc5aebb9-28e2-4eb8-d529-fe38309894b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 290315 entries, 0 to 290314\n",
      "Data columns (total 51 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   Additional_Number_of_Scoring                290315 non-null  float64\n",
      " 1   Review_Date                                 290315 non-null  float64\n",
      " 2   Average_Score                               290315 non-null  float64\n",
      " 3   Hotel_Name_0                                290315 non-null  int64  \n",
      " 4   Hotel_Name_1                                290315 non-null  int64  \n",
      " 5   Hotel_Name_2                                290315 non-null  int64  \n",
      " 6   Hotel_Name_3                                290315 non-null  int64  \n",
      " 7   Hotel_Name_4                                290315 non-null  int64  \n",
      " 8   Hotel_Name_5                                290315 non-null  int64  \n",
      " 9   Hotel_Name_6                                290315 non-null  int64  \n",
      " 10  Hotel_Name_7                                290315 non-null  int64  \n",
      " 11  Hotel_Name_8                                290315 non-null  int64  \n",
      " 12  Hotel_Name_9                                290315 non-null  int64  \n",
      " 13  Hotel_Name_10                               290315 non-null  int64  \n",
      " 14  Reviewer_Nationality_0                      290315 non-null  int64  \n",
      " 15  Reviewer_Nationality_1                      290315 non-null  int64  \n",
      " 16  Reviewer_Nationality_2                      290315 non-null  int64  \n",
      " 17  Reviewer_Nationality_3                      290315 non-null  int64  \n",
      " 18  Reviewer_Nationality_4                      290315 non-null  int64  \n",
      " 19  Reviewer_Nationality_5                      290315 non-null  int64  \n",
      " 20  Reviewer_Nationality_6                      290315 non-null  int64  \n",
      " 21  Reviewer_Nationality_7                      290315 non-null  int64  \n",
      " 22  Negative_Review                             290315 non-null  float64\n",
      " 23  Review_Total_Negative_Word_Counts           290315 non-null  float64\n",
      " 24  Total_Number_of_Reviews                     290315 non-null  float64\n",
      " 25  Positive_Review                             290315 non-null  float64\n",
      " 26  Review_Total_Positive_Word_Counts           290315 non-null  float64\n",
      " 27  Total_Number_of_Reviews_Reviewer_Has_Given  290315 non-null  float64\n",
      " 28  days_since_review                           290315 non-null  float64\n",
      " 29  lat                                         290315 non-null  float64\n",
      " 30  lng                                         290315 non-null  float64\n",
      " 31  Review_month                                290315 non-null  float64\n",
      " 32  trip_type                                   290315 non-null  float64\n",
      " 33  duration                                    290315 non-null  float64\n",
      " 34  room_type_0                                 290315 non-null  int64  \n",
      " 35  room_type_1                                 290315 non-null  int64  \n",
      " 36  room_type_2                                 290315 non-null  int64  \n",
      " 37  bed_type                                    290315 non-null  int64  \n",
      " 38  submit                                      290315 non-null  float64\n",
      " 39  Hotel_Address_Austria                       290315 non-null  uint8  \n",
      " 40  Hotel_Address_France                        290315 non-null  uint8  \n",
      " 41  Hotel_Address_Italy                         290315 non-null  uint8  \n",
      " 42  Hotel_Address_Netherlands                   290315 non-null  uint8  \n",
      " 43  Hotel_Address_Spain                         290315 non-null  uint8  \n",
      " 44  Hotel_Address_United Kingdom                290315 non-null  uint8  \n",
      " 45  customer_type_ Couple                       290315 non-null  uint8  \n",
      " 46  customer_type_ Family with older children   290315 non-null  uint8  \n",
      " 47  customer_type_ Family with young children   290315 non-null  uint8  \n",
      " 48  customer_type_ Group                        290315 non-null  uint8  \n",
      " 49  customer_type_ Solo traveler                290315 non-null  uint8  \n",
      " 50  customer_type_ Travelers with friends       290315 non-null  uint8  \n",
      "dtypes: float64(16), int64(23), uint8(12)\n",
      "memory usage: 89.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mS2vk0k1DMLn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mS2vk0k1DMLn",
    "outputId": "0dfb26f9-6c85-461f-cb2a-2bedf9bd3028"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "160 fits failed out of a total of 320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.6659792  0.66655615 0.66738284 0.66933331 0.66827412 0.67080154\n",
      " 0.66957012 0.67242047 0.66618156 0.66860996 0.66767132 0.6704657\n",
      " 0.66935484 0.67065946 0.66981124 0.67087905 0.66733979 0.67111155\n",
      " 0.66814064 0.67094794 0.6687951  0.67052167 0.67009541 0.66825689\n",
      " 0.66898025 0.64081257 0.66891566 0.65189105 0.6694754  0.67275201\n",
      " 0.67012125 0.67212338 0.6696304  0.64181148 0.66976388 0.64371889\n",
      " 0.66996624 0.67292424 0.67041834 0.67381551        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.66578975 0.66639254 0.66737423 0.66955721\n",
      " 0.66863149 0.67111155 0.67018153 0.67233436 0.66658629 0.67048292\n",
      " 0.66763257 0.66777466 0.66907928 0.67185213 0.6704657  0.67141725\n",
      " 0.66760243 0.6704614  0.66867024 0.66716756 0.66967776 0.67292424\n",
      " 0.67062932 0.67355286 0.66913525 0.65653687 0.66906636 0.67065946\n",
      " 0.66975527 0.65809121 0.67095655 0.67331605 0.66982416 0.67247645\n",
      " 0.6697079  0.6658285  0.67063793 0.67126225 0.67132253 0.67347106\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "36 fits failed out of a total of 54.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.67892203 0.68136335 0.68127293\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.56987238 0.67846133 0.6813289         nan        nan        nan\n",
      "        nan        nan        nan 0.56987238 0.56987238 0.56987238\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "6 fits failed out of a total of 12.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.68007165        nan 0.68001137        nan 0.67974872]\n",
      "  warnings.warn(\n",
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_Accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.673816</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 1, 'min_...</td>\n",
       "      <td>11.255920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.681363</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'n_...</td>\n",
       "      <td>273.326578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>14.251302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  best_Accuracy                                        best_params  \\\n",
       "0        DT       0.673816  {'criterion': 'gini', 'max_features': 1, 'min_...   \n",
       "1       GBC       0.681363  {'learning_rate': 0.1, 'loss': 'deviance', 'n_...   \n",
       "2  logistic       0.680072                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "\n",
       "   train_time  \n",
       "0   11.255920  \n",
       "1  273.326578  \n",
       "2   14.251302  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy = [] #an empty array to store the (modelname,Accuracy of model,best parameters)\n",
    "trainedModels = list()\n",
    "for name,mp in classification_model.items() : #for loop used to iterate over all the models we have in (parameters_model)\n",
    "  start_time = time.time()\n",
    "  classification = GridSearchCV(mp['model'],mp['params'],cv = 2,return_train_score= False) #using GridSearch to get the best parameters for each model\n",
    "  #CV: number of cross-validations(b2sm al training set l subsets w a3od a3ml train 3leha)(n Combination)\n",
    "  print(name)\n",
    "  classification.fit(X_train,Y_train) #train the model\n",
    "  pickle.dump(classification, open(name + '.sav', 'wb'))\n",
    "  trainedModels.append({'name':name,'model': classification})\n",
    "  Accuracy.append({\n",
    "      'model':name, #model name\n",
    "      'best_params': classification.best_params_, #best parameters of the model\n",
    "      'best_Accuracy':classification.best_score_, #best score of the model\n",
    "      'train_time' : time.time() - start_time, #total train time of the model\n",
    "      **classification.cv_results_\n",
    "  })\n",
    "newdf = pd.DataFrame(Accuracy,columns = ['model','best_Accuracy','best_params','train_time']) #put the array in a new dataframe\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "573fdd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'loss': 'deviance', 'n_estimators': 100}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf['best_params'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eERofZNMFb-u",
   "metadata": {
    "id": "eERofZNMFb-u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model', ylabel='best_Accuracy'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x = newdf['model'],y = newdf['best_Accuracy'],data = newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135ec8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81dfb218",
   "metadata": {
    "id": "81dfb218"
   },
   "source": [
    "# **Evaluate Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cCa24q8pOzOR",
   "metadata": {
    "id": "cCa24q8pOzOR"
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563e8e8f",
   "metadata": {
    "id": "563e8e8f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Evaluate(model,modelName,testSet,actualSet):\n",
    "    predicted = model.predict(testSet)\n",
    "    mse = mean_squared_error(actualSet,predicted)\n",
    "    r2 = r2_score(actualSet,predicted)\n",
    "    print(modelName,\": \")\n",
    "    print(\"MSE = \" , mse)\n",
    "    print(\"R2 Score: \" , r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4358714d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mEvaluate\u001b[49m(randomModel,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m,XtestForest,YtestForest)\n\u001b[0;32m      2\u001b[0m Evaluate(treeModel,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m,XtestForest,YtestForest)\n\u001b[0;32m      3\u001b[0m Evaluate(linearModel,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m,XtestLinear,YtestLinear)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "Evaluate(randomModel,\"Random Forest\",XtestForest,YtestForest)\n",
    "Evaluate(treeModel,\"Decision Tree\",XtestForest,YtestForest)\n",
    "Evaluate(linearModel,\"Linear Regression\",XtestLinear,YtestLinear)\n",
    "Evaluate(polyModel,\"Polynomial Regression\",XtestPolynomial,YtestPolynomial)\n",
    "Evaluate(gradientModel,\"Gradient Boost\",XtestGradient,YtestGradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3G8YLHv3PmqG",
   "metadata": {
    "id": "3G8YLHv3PmqG"
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "-SN5dk4QPmDb",
   "metadata": {
    "id": "-SN5dk4QPmDb"
   },
   "outputs": [],
   "source": [
    "def Evaluate_accuracy(model,modelName,testSet,actualSet):\n",
    "    start_time = time.time()\n",
    "    predicted = model.predict(testSet)\n",
    "    acc = accuracy_score(actualSet,predicted)\n",
    "    test_time = time.time() - start_time\n",
    "    print(modelName,\": \")\n",
    "    print(\"Accuracy = \" , acc)\n",
    "    return test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate your model here\n",
    "test_times = list()\n",
    "for i in trainedModels:\n",
    "  test_time = Evaluate_accuracy(i['model'],i['name'],X_test,Y_test)\n",
    "  test_times.append(test_time)\n",
    "newdf.insert(1,'test_time',test_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9408f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(newdf['model'], newdf['train_time'], data = newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06408c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(newdf['model'], newdf['test_time'], data = newdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HJINe7lp9gSb",
   "metadata": {
    "id": "HJINe7lp9gSb"
   },
   "source": [
    "# **Test Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "k-P290pZ9qOx",
   "metadata": {
    "id": "k-P290pZ9qOx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Personal\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:  : \n",
      "MSE =  3546.831531264638\n",
      "R2 Score:  -73736.5361899612\n",
      "Polynomial Regression:  : \n",
      "MSE =  0.028081054195261048\n",
      "R2 Score:  0.4162035237018906\n",
      "DecisionTreeRegressor.sav : \n",
      "MSE =  0.02975112763104935\n",
      "R2 Score:  0.38148321084637027\n",
      "random_model.sav : \n",
      "MSE =  0.028283523696202576\n",
      "R2 Score:  0.41199424507632365\n",
      "GradientBoostingRegressor.sav : \n",
      "MSE =  0.02709071058423318\n",
      "R2 Score:  0.436792462650628\n",
      "DT.sav : \n",
      "Accuracy =  0.648\n",
      "GBC.sav : \n",
      "Accuracy =  0.663\n",
      "logistic.sav : \n",
      "Accuracy =  0.662\n"
     ]
    }
   ],
   "source": [
    "regressionModels = ['DecisionTreeRegressor.sav','random_model.sav','GradientBoostingRegressor.sav']\n",
    "classificationsModels = ['DT.sav','GBC.sav','logistic.sav']\n",
    "root = Tk()\n",
    "root.title = (\"Regression Test Set\")\n",
    "file_path = filedialog.askopenfilename(filetypes=[('CSV Files', '*.csv')],parent = root)\n",
    "df = pd.read_csv(file_path)\n",
    "#Regression\n",
    "df = Preprocessing(df)\n",
    "Y = df['Reviewer_Score']\n",
    "df_linear = pd.DataFrame.copy(df)\n",
    "df_linear = EncodeLR(df_linear)\n",
    "X_linear = df_linear.iloc()[: , [0,2,3,4,5,6,8,9,11,14,15,19,22,23,28,29]]\n",
    "linear_model = pickle.load(open('linear_Model.sav','rb'))\n",
    "Evaluate(linear_model,\"LinearRegression: \",X_linear,Y)\n",
    "numerical_features = GetNumericalFeatures(df)\n",
    "X = EncodeGB(df.drop('Reviewer_Score',axis=1))\n",
    "X = SelectFeatures(X,Y,r_regression,3,f_classif,2,numerical_features,'selectedFeatures.sav')\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "model = pickle.load(open('Polynomial Regression.sav','rb'))\n",
    "Evaluate(model,'Polynomial Regression: ',X_poly,Y)\n",
    "for i in regressionModels:\n",
    "    model = pickle.load(open(i,'rb'))\n",
    "    Evaluate(model,i,X,Y)\n",
    "#Classification\n",
    "file_path = filedialog.askopenfilename(filetypes=[('CSV Files', '*.csv')],parent = root)\n",
    "df = pd.read_csv(file_path)\n",
    "df = Preprocessing(df)\n",
    "Y = df['Reviewer_Score']\n",
    "numerical_features = GetNumericalFeatures(df)\n",
    "X = EncodeGB(df.drop('Reviewer_Score',axis = 1))\n",
    "YEncoder = pickle.load(open('classificationEncoder.sav','rb'))\n",
    "Y = YEncoder.transform(Y.to_numpy().reshape(-1,1))\n",
    "X = SelectFeatures(X,Y,r_regression,3,f_classif,2,numerical_features,'classifselectedFeatures.sav')\n",
    "for i in classificationsModels:\n",
    "    model = pickle.load(open(i,'rb'))\n",
    "    Evaluate_accuracy(model,i,X,Y)\n",
    "root.destroy()\n",
    "#def filesopener(path,name) :\n",
    "# pickle_file_path = path\n",
    "# Load the data from the pickle file\n",
    "# with open(pickle_file_path, 'rb') as file:\n",
    "#     name = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b7e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d2e2e558",
    "8c36898b",
    "0fdd35be",
    "23b9e235",
    "c501f2de",
    "33d338aa",
    "a3a5d92c",
    "97cbf165",
    "e38ded53"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
